{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yahoo finance data\n",
    "import yfinance as yf\n",
    "# import stockstats data\n",
    "from stockstats import StockDataFrame as ss\n",
    "\n",
    "# import necessary libraries\n",
    "import matplotlib as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "import statistics\n",
    "import pydoc\n",
    "import os\n",
    "import pyarrow\n",
    "import pandas_gbq\n",
    "import statsmodels\n",
    "import tensorflow\n",
    "\n",
    "#import libraries for SARIMA model\n",
    "import pmdarima as pm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Data for Apple Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_ticker = yf.Ticker(\"AAPL\")\n",
    "apple_data = yf.download(\"AAPL\", start = '2020-01-01', interval = '1d')\n",
    "apple_df = ss.retype(apple_data)\n",
    "\n",
    "apple_data[['stochrsi', 'macd', 'mfi']] = apple_df[['stochrsi', 'macd', 'mfi']]\n",
    "print(apple_data)\n",
    "print(apple_ticker.get_capital_gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data Into SQL -> BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/cloud-platform',\n",
    "    'https://www.googleapis.com/auth/drive',\n",
    "]\n",
    "\n",
    "# import google cloud service account and bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# specify google cloud project information\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    'black-vehicle-406619-bf2e31773163.json')\n",
    "project_id = 'black-vehicle-406619'\n",
    "client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "dataset_id = 'stocks_ds'\n",
    "table_id = '20yrs_stockdata'\n",
    "table_path = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "# specify load reqs\n",
    "load_info = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "load_data = client.load_table_from_dataframe(apple_data, table_path, job_config=load_info)\n",
    "load_data.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Data: SARIMA Model\n",
    "\n",
    "- Using indexing to remove duplicates, therefore preventing bias and skewing the distrubotion of the data.\n",
    "- Training the model on close prices only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seasonal - fit stepwise auto-ARIMA\n",
    "#!pip install pmdarima\n",
    "\n",
    "# Remove any duplicate index\n",
    "apple_data = apple_data.loc[~apple_data.index.duplicated(keep='first')]\n",
    "\n",
    "#Filter only required data\n",
    "\n",
    "apple_data = apple_data[['Close']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Data: SARIMA Model\n",
    "- Created an instance of MinMaxScaler class to use while creating a new DataFrame.\n",
    "- We are scaling Apple's stock prices to a range between 0 and 1 for the LTSM model. By doing so, we are improving learning stability and the speed of the model, also creating numerical stability.\n",
    "\n",
    "- Feature_Scaler.fit_transform(apple_data) scales the 'Close' column of the apple_data DataFrame using the fit_transform method. This method fits the scaler to the data and transforms it in a single step.\n",
    "- Used np.squeeze to reshape the result from the scaler, removing any unnecessary dimensions.\n",
    "- Created DataFrame \"apple_transformed\", while specifying the column to be named Close and ensure the index matches the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the APPL data into a standard range using MinMaxScaler ()\n",
    "\n",
    "Feature_Scaler = MinMaxScaler()\n",
    "\n",
    "#Transform current APPL data\n",
    "\n",
    "apple_transformed = pd.DataFrame(np.squeeze(Feature_Scaler.fit_transform(apple_data), axis=1), columns=[\"Close\"], index=apple_data.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating SARIMA Model\n",
    "- `pm.auto_arima` function is used to fit a Seasonal ARIMA model to the 'Close' price data of Apple stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sarima_model = pm.auto_arima(apple_transformed[\"Close\"], start_p=1, start_q=1,\n",
    "                         test='adf',\n",
    "                         max_p=3, max_q=3,\n",
    "                         m=12, #12 is the frequency of the cycle (yearly)\n",
    "                         start_P=0,\n",
    "                         seasonal=True, #set to seasonal\n",
    "                         d=None,\n",
    "                         D=1, #order of the seasonal differencing\n",
    "                         trace=False,\n",
    "                         error_action='ignore',\n",
    "                         suppress_warnings=True,\n",
    "                         stepwise=True)\n",
    "\n",
    "# start_p=1, start_q=1: Sets the initial values for the order of the AR (AutoRegressive) and MA (Moving Average) components in the non-seasonal part of the model.\n",
    "# test='adf': Specifies the use of the Augmented Dickey-Fuller (ADF) test to determine whether the time series is stationary and to help in determining the need for differencing (`d` parameter).\n",
    "# max_p=3, max_q=3: Specifies the maximum values for the `p` and `q` parameters to consider during the model fitting process.\n",
    "# start_P=0: Sets the initial value for the order of the seasonal AR component.\n",
    "# d=None: The order of non-seasonal differencing is not specified, which allows the function to determine it automatically.\n",
    "# trace=False: This means that the function will not print out diagnostic information about the steps it's taking.\n",
    "# error_action='ignore': Instructs the function to ignore errors and try different combinations of parameters.\n",
    "# suppress_warnings=True: Suppresses convergence warnings, which can be frequent in ARIMA modeling.\n",
    "# stepwise=True: Enables a stepwise search to efficiently find the best model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMA Model: Create diagnostic plots\n",
    "- Residual Plot\n",
    "- Histrogram Plot\n",
    "- Normal Q-Q Plot\n",
    "- Correlogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_model.plot_diagnostics(figsize=(15,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMA Model: Serialize with `Pickle`\n",
    "- Serializing = Converting the model object into a format that can be easily stored in a file for later use or sharing without having to retrain.\n",
    "- Pickle allows the use of 'wb' and 'rb' modes to open a file for reading or writing in binary mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize with Pickle and save it as pkl\n",
    "with open('sarima_model.pkl', 'wb') as pkl:\n",
    "    pickle.dump(sarima_model, pkl)\n",
    "\n",
    "# Desiarilize the content of the file back into a Python object\n",
    "with open('sarima_model.pkl', 'rb') as pkl:\n",
    "    loaded_model = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMA Model: Predicting APPL Stock Price\n",
    "- Define a function named forecast that takes a time series model, a DataFrame (df), and a forecast date as input, and returns a DataFrame containing actual values, predicted values, and confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, df, forecast_date):\n",
    "    # Forecast\n",
    "    n_periods = (datetime.strptime(forecast_date, '%Y-%m-%d') - df.index[-1]).days\n",
    "    fitted, confint = model.predict(n_periods=n_periods, return_conf_int=True)\n",
    "    index_of_fc = pd.date_range(df.index[-1] + pd.DateOffset(days=1), periods = n_periods, freq='D')\n",
    "\n",
    "    # Make series for plotting purpose\n",
    "    fitted_series = pd.Series(fitted.values, index=index_of_fc)\n",
    "    lower_series = pd.Series(confint[:, 0], index=index_of_fc)\n",
    "    upper_series = pd.Series(confint[:, 1], index=index_of_fc)\n",
    "\n",
    "    #Concatenate the original DataFrame with forecasted values and confidence intervals\n",
    "    df_result = pd.concat([df, fitted_series, lower_series, upper_series], axis=1)\n",
    "    df_result.columns = [\"Actual\", \"Prediction\", \"Low\", \"High\"]\n",
    "\n",
    "    #Inverse transform the scaled values to their original scale\n",
    "    for column in df_result.columns:\n",
    "      df_result[column] = Feature_Scaler.inverse_transform(df_result[column].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMA Model: Store APPL Stock Price\n",
    "- Use the above defined function to store your predicted values in a `test` variable\n",
    "- View what is stored in `test` variable\n",
    "- Plot the range of predicted prices for APPL stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=forecast(loaded_model, apple_transformed, \"2023-12-20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(test[\"Actual\"][-120:], color='#1f76b4')\n",
    "plt.plot(test[\"Prediction\"], color='darkgreen')\n",
    "plt.fill_between(test.index,\n",
    "                test[\"Low\"],\n",
    "                test[\"High\"],\n",
    "                color='k', alpha=.15)\n",
    "\n",
    "plt.title(\"SARIMA - Forecast of APPL Stock Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Predicted Data into BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# specify google cloud project information\n",
    "dataset_id = 'predicted_prices'\n",
    "table_id = 'SARIMA and LTSM Predicted Prices'\n",
    "table_path = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "# specify load reqs\n",
    "load_info = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "# enter combined data load_data = client.load_table_from_dataframe(combined data, table_path, job_config=load_info)\n",
    "load_data.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
