{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Forecasting with the SARIMA Model\n",
    "\n",
    "## Summary\n",
    "\n",
    "**SARIMA Model:** Seasonal Autoregressive Integrated Moving Average (SARIMA) model, a time series forecasting method, is implemented to capture the underlying patterns and trends in the stock price data.\n",
    "\n",
    "The Seasonal Autoregressive Integrated Moving Average (SARIMA) model provides a robust framework for predicting stock prices. SARIMA's ability to capture the seasonal patterns and cyclic behavior inherent in sequential data, combined with its foundation in statistical time series analysis principles, enhances the credibility of our predictions. The model's interpretable parameters provide a deeper understanding of the underlying dynamics driving stock price movements. However, it is important to note SARIMA's limitation in capturing external factors, such as news events or sudden market shocks, which may affect stock prices but are not directly incorporated into the model. Despite this limitation, SARIMA remains a valuable tool for predicting stock prices based on historical patterns and internal data dynamics.\n",
    "\n",
    "For this project, four time ranges of historical data were evaluated to assess the accuracy of the SARIMA models' predictions for three different stocks (AAPL, TSLA, and NVDA).\n",
    "\n",
    "Predicted Dates: 06-01-2024 to 06-11-2024\n",
    "\n",
    "Historical Data Time Ranges:\n",
    "\n",
    "1. 01-01-2015 to 5-31-2024\n",
    "2. 01-01-2017 to 5-31-2024\n",
    "3. 01-01-2029 to 5-31-2024\n",
    "4. 01-01-2021 to 5-31-2024\n",
    "\n",
    "From these time ranges, the amount of historical data that provided the most accurate predictions was determined using comparison metrics such as R-squared, p-value, RMSE, MSE, MAPE, AIC, and BIC.\n",
    "\n",
    "\n",
    "\n",
    "## Evaluating the Usefulness of the SARIMA Model for a Company's Toolkit\n",
    "Is the SARIMA model useful for your company's toolkit? \n",
    "\n",
    "The finalized predictive model was thoroughly tested and found to have excellent accuracy, averaging 96.8% for the recent time ranges (2019, 2021). Therefore, the SARIMA model is a valuable addition to a company's toolkit.\n",
    "\n",
    "Factors for Selecting Time Ranges:\n",
    "1. Accuracy (RMSE, MSE, MAPE)\n",
    "2. Speed\n",
    "3. Compute resource usage considerations\n",
    "4. Reproducibility\n",
    "5. World Events\n",
    "6. Other factors\n",
    "\n",
    "**Selected Model:** The SARIMA models for AAPL, NVDA, and TSLA, using the most recent historical data time ranges (2019, 2021), were chosen because:\n",
    "- They demonstrated high accuracy in capturing seasonal trends and underlying patterns in stock data.\n",
    "- They provided interpretable parameters that offered valuable insights into stock price movements.\n",
    "\n",
    "Other time ranges (2015, 2017) were less effective because:\n",
    "- They showed slower computation times.\n",
    "- They had lower accuracy metrics compared to recent time ranges.\n",
    "- They required more computational resources, making them less practical for real-time stock prediction.\n",
    "\n",
    "### A Detailed Analysis of SARIMA's Superiority Over Other Forecasting Methods\n",
    "\n",
    "Time Series Prediction vs. Other Machine Learning Tasks: SARIMA excels in time series analysis, making it highly effective for stock price predictions, where the temporal dependencies of historical data play a crucial role. In contrast, other machine learning models may struggle to capture these temporal patterns as effectively.\n",
    "\n",
    "Specifics of the Model:\n",
    "\n",
    "- SARIMA: Captures seasonality and trends in data, making it robust for stocks with clear cyclical patterns, such as AAPL and TSLA. By leveraging its interpretable parameters, SARIMA provides a nuanced understanding of stock price movements and helps identify recurring trends.\n",
    "\n",
    "- Contextual Effectiveness:\n",
    "SARIMA's ability to effectively utilize recent historical data has proven beneficial for stable stocks like AAPL. However, for more volatile stocks like NVDA and TSLA, the model's performance was enhanced by incorporating longer historical data, which improved prediction accuracy by accounting for more complex stock price fluctuations.\n",
    "\n",
    "The Disadvantages of Other Models:\n",
    "\n",
    "1. **ARIMA (Autoregressive Integrated Moving Average)**:\n",
    "   - While ARIMA is effective for univariate time series data, it lacks the capability to model seasonal patterns as effectively as SARIMA. SARIMA extends ARIMA by incorporating seasonal components, making it more suitable for datasets with clear seasonal trends, such as stock prices.\n",
    "\n",
    "2. **GARCH (Generalized Autoregressive Conditional Heteroskedasticity)**:\n",
    "   - GARCH models focus primarily on modeling volatility and are useful for forecasting the variance of returns rather than predicting actual prices. They are not designed for point forecasts of stock prices, limiting their applicability for direct price prediction tasks.\n",
    "\n",
    "3. **XGBoost**:\n",
    "   - XGBoost is a powerful machine learning algorithm that excels in classification and regression tasks. However, it does not inherently account for the temporal dependencies in time series data. Without careful feature engineering to incorporate time-based features, it may not perform as well for stock price predictions as SARIMA, which directly models these temporal relationships.\n",
    "\n",
    "4. **Random Forest**:\n",
    "   - Like XGBoost, Random Forest is a robust model for various prediction tasks but does not leverage the sequential nature of time series data. While it can provide accurate predictions with sufficient data, it typically requires extensive feature engineering to capture the temporal dynamics, which is automatically handled by SARIMA.\n",
    "\n",
    "5. **TBATS (Trigonometric, Box-Cox Transformation, ARMA Errors, Trend, and Seasonal Components)**:\n",
    "   - TBATS is designed for complex seasonal patterns, but it can be computationally intensive and may require tuning of multiple parameters. In contrast, SARIMA offers a more straightforward framework for seasonal data without needing as much computational overhead.\n",
    "\n",
    "6. **Prophet**:\n",
    "   - Prophet is user-friendly and effective for forecasting time series data with strong seasonal effects and missing values. However, it may not be as robust for datasets with less clear seasonal patterns or when high-frequency forecasting is needed. SARIMA, with its statistical basis, can provide more granular control over the model parameters for precise forecasting.\n",
    "\n",
    "### Conclusion\n",
    "While each of these models has its strengths, they may not capture the intricate seasonal patterns and temporal relationships present in stock price data as effectively as SARIMA. SARIMAâ€™s design specifically caters to time series forecasting, allowing for more reliable predictions in financial contexts, particularly when historical data plays a critical role.\n",
    "\n",
    "## Process Overview\n",
    "\n",
    "### Final Workflow Summary for AAPL, NVDA, and TSLA Stock Predictions\n",
    "\n",
    "Utilizing historical stock price data from 2021 (AAPL, TSLA) and 2019 (NVDA), the SARIMA model was applied. Key packages such as statsmodels, pandas, and matplotlib were used to generate the most accurate predictions, with results visualized using matplotlib.\n",
    "\n",
    "The evaluation metrics employed include Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and prediction accuracy.\n",
    "\n",
    "**Definition of Accuracy:** In this context, accuracy refers to how closely the SARIMA model's predicted values match the actual observed stock prices, as measured by low MSE, RMSE, and MAPE scores.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step-by-Step Guide to Implementing the SARIMA Model\n",
    "Step 1: Necessary packages were imported into Python. Packages important to note were pandas, numpy, yfinance, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import packages\n",
    "# % pip install pandas\n",
    "# % pip install numpy\n",
    "# % pip install plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pmdarima as pm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: The user input was taken by selecting a stock, and multiple years of historical data for the selected stock were downloaded and stored in the stock_select_str variable. In this case, the stock was AAPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: User input for stock ticker\n",
    "stock_select_str = input(\"Enter stock ticker: \")\n",
    "\n",
    "# Initial load run\n",
    "stock_data = yf.download(stock_select_str, start='2021-01-01', end='2024-05-31', interval='1d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: The historical data for AAPL was checked before processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Check data before processing\n",
    "print(stock_data.head())\n",
    "print(stock_data.info())\n",
    "print(stock_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps 4 and 5: The historical data was processed by the SARIMA model.\n",
    "\n",
    "Step 4: The index of the stock_data DataFrame was first converted to a DateTimeIndex to enable easy filtering. Then, weekend data was filtered out by retaining only rows where the day of the week was less than 5 (Monday to Friday).\n",
    "\n",
    "Step 5: The process_model function was defined to create and configure a SARIMA (Seasonal AutoRegressive Integrated Moving Average) model. The function took stock_transformed as input and processed its \"Close\" price data. The auto_arima function was set up to optimize the SARIMA model parameters (like p, q, P, and Q) with specific settings: a yearly seasonal cycle (m=12), seasonal differencing of order 1, and stepwise selection for efficiency. After fitting, the model was returned for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Process data\n",
    "# Ensure the index is a DateTimeIndex for easy filtering\n",
    "stock_data.index = pd.to_datetime(stock_data.index)\n",
    "\n",
    "# Filter out weekends\n",
    "stock_data = stock_data[stock_data.index.to_series().dt.dayofweek < 5]\n",
    "\n",
    "# Step 5: Define the process_model function\n",
    "def process_model(stock_transformed):\n",
    "    print(\"Processing SARIMA model...\\n\")\n",
    "    \n",
    "    sarima_model = pm.auto_arima(stock_transformed[\"Close\"], start_p=1, start_q=1,\n",
    "                                  test='adf',\n",
    "                                  max_p=3, max_q=3,\n",
    "                                  m=12,  # 12 is the frequency of the cycle (yearly)\n",
    "                                  start_P=0,\n",
    "                                  seasonal=True,  # Set to seasonal\n",
    "                                  d=None,\n",
    "                                  D=1,  # Order of the seasonal differencing\n",
    "                                  trace=False,\n",
    "                                  error_action='ignore',\n",
    "                                  suppress_warnings=True,\n",
    "                                  stepwise=True)\n",
    "    \n",
    "    return sarima_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the SARIMA model\n",
    "sarima_model = process_model(stock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: The predictions were run by calling a built-in predict function. The n_forecast variable is 12 because of the number of days to forecast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Run predictions\n",
    "n_forecast = 12\n",
    "forecast, conf_int = sarima_model.predict(n_periods=n_forecast, return_conf_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: The output was assessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Assess output\n",
    "print(f\"Forecasted values: {forecast}\")\n",
    "print(f\"Confidence intervals: {conf_int}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Chart Actuals Against Forecast\n",
    "Actual closing prices were imported for the stock AAPL into the real_values DataFrame, using data up to June 12, 2024. It then filtered this data to include only the closing prices from January 1 to June 11, 2024, which were stored in plot_real.\n",
    "\n",
    "A plot was created with a figure size of 12x8 inches, displaying the historical closing prices alongside the forecasted closing prices. The forecast was plotted starting from June 1, 2024, extending for the specified number of forecasted days (n_forecast) on business days (freq='B'). A shaded area representing the 95% confidence interval was added around the forecast line. Finally, the x-axis range was set from April 1 to June 11, 2024, and labels for the title, x-axis, y-axis, and legend were included for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Visualize\n",
    "# Import actual closing prices into real_values dataframe\n",
    "real_values = yf.download(\"AAPL\", end='2024-06-12')\n",
    "plot_real = real_values.loc['2024-01-01':'2024-06-11', 'Close']\n",
    "    \n",
    "# Plot the extended historical data\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(plot_real, label='Historical Close Prices')\n",
    "plt.plot(pd.date_range(start='2024-06-01', periods=n_forecast, freq='B'), \n",
    "         forecast, label='Forecasted Close Prices', color='orange')\n",
    "plt.fill_between(pd.date_range(start='2024-06-01', periods=n_forecast, freq='B'), \n",
    "                 conf_int[:, 0], conf_int[:, 1], color='gray', alpha=0.5, label='95% Confidence Interval')\n",
    "\n",
    "# Adjust the x-axis and other labels\n",
    "plt.xlim(pd.Timestamp('2024-04-01'), pd.Timestamp('2024-06-11'))\n",
    "plt.title(f'Close Price Forecast for {stock_select_str}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: \n",
    "The print_metrics function outputs the chosen comparison metrics for determining accuracy (RMSE, MSE, and MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(actual, predicted):\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    \n",
    "    # Calculate MAPE (Mean Absolute Percentage Error)\n",
    "    actual_values = np.array(actual)\n",
    "    predicted_values = np.array(predicted)\n",
    "    mape = np.mean(np.abs((actual_values - predicted_values) / actual_values[actual_values != 0])) * 100 if np.any(actual_values != 0) else np.nan\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Example usage (assuming 'forecast' and 'plot_real[-n_forecast:]' are defined)\n",
    "print_metrics(plot_real[-n_forecast:], forecast)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
