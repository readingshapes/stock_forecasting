{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Your Audience Cares About:\n",
    "1. can you help me do a thing?\n",
    "2. how can your thing help me do better at my thing?\n",
    "3. how can i trust your recommendation?\n",
    "4. prove your recommendation in a way i understand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# title\n",
    "\n",
    "## summary\n",
    "### question\n",
    "    - answer\n",
    "### why the answer\n",
    "    - parameters for selection:\n",
    "        1. accurate (for use case)\n",
    "        2. faster\n",
    "        3. compute resource usage considerations\n",
    "        4. reproduceability\n",
    "        5. other\n",
    "    - selected model x because:\n",
    "        - faster\n",
    "        - more accurate\n",
    "        - less resource use\n",
    "    - model y, z weren't as good because:\n",
    "        - slower\n",
    "        - less accurate\n",
    "        - more resource intensive\n",
    "#### a little more detail about why not other answers and methods (context)\n",
    "    - time series prediction vs other machine learning tasks\n",
    "    - specifics of these models - which ones work better and why\n",
    "    - model x\n",
    "    - model y, z, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how\n",
    "- high level: describe final process:  \n",
    "based on data set [A], used model [x], packages [b,c,d] to create [E], then visuzalized using package [f]   \n",
    "\n",
    "data set A uses definitions 1, 2, and 3  \n",
    "\n",
    "Definition of accuracy:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate HOW using code\n",
    "\n",
    "# import packages\n",
    "\n",
    "# read in data\n",
    "\n",
    "# check data before processing\n",
    "\n",
    "# process data\n",
    "\n",
    "# adjust model as needed\n",
    "\n",
    "# run\n",
    "\n",
    "# assess output\n",
    "\n",
    "# visualize\n",
    "\n",
    "# output data and charts somewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare and Select best model for forecasting stocks\n",
    "- last updated: 2024-09-05\n",
    "## summary\n",
    "Select stock forecasting model that has the best possible prediction of the change in the stock price of the next day.\n",
    "### Which time-series based forecasting model works best to predict stocks?\n",
    "    - answer\n",
    "### why the answer\n",
    "for this project we looked at LSTM and SARIMA models.  \n",
    "    - parameters for selection:\n",
    "        1. accurate (for use case)\n",
    "        2. faster\n",
    "        3. compute resource usage considerations\n",
    "        4. reproduceability\n",
    "        5. consistency\n",
    "        6. supervised vs unsupervised, and why\n",
    "    - selected model x because:\n",
    "        - faster\n",
    "        - more accurate\n",
    "        - less resource use\n",
    "    - model y, z weren't as good because:\n",
    "        - slower\n",
    "        - less accurate\n",
    "        - more resource intensive\n",
    "#### a little more detail about why not other answers and methods (context)\n",
    "- time series prediction vs other machine learning tasks - [check out this excellent article for structure](https://neptune.ai/blog/select-model-for-time-series-prediction-task)  \n",
    "> In time series, however, observations are measured over time. Each data point in your data set corresponds to a point in time. This means that there is a relation between different data points of your dataset. This has important implications for the types of machine learning algorithms that you can apply to the time series dataset.  \n",
    "\n",
    "- univariate vs multivariate:\n",
    "\n",
    "> Time Series Decomposition is a technique to extract multiple types of variation from your dataset. There are three important components in the temporal data of a time series: seasonality, trend, and noise.  \n",
    "- seasonality:\n",
    "- trend: \n",
    "- noise:\n",
    "\n",
    "> time series considerations for your data set type:\n",
    "- autocorrelation: past predicts future\n",
    "- stationarity: test stability of data set\n",
    "- single or multi-step predictions; lag window defintions \n",
    "   \n",
    "#### specifics of these models - which ones work better and why, and what parameters we chose:  \n",
    "- LSTM: (l)ong (s)hort (t)erm (m)emory\n",
    "    - RNN: recurrent neural network\n",
    "    - each node in network handles one thing  \n",
    "    - good for very complex, nonlinear data\n",
    "    - learns over sequences (e.g., time series)\n",
    "- SARIMA: (s)easonal + (i)ntegrated + (a)uto (r)egression + (m)oving (a)verage\n",
    "    - p = number of lagged values included:\n",
    "    - q = number of time steps in moving average:\n",
    "    - d = number of differencing sequences: \n",
    "    - m = number of observations per year:\n",
    "    - smoothing choice: \n",
    "    - final model choice: SARIMA(p, d, q)(P, D, Q)m\n",
    "\n",
    "#### why not other models?\n",
    "- GARCH\n",
    "- XGBoost\n",
    "- Random Forest\n",
    "- TBATS \n",
    "- prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how\n",
    "- high level: describe final process:  \n",
    "based on data set [Apple stock from yahoo finance api], used model [x], packages [b,c,d] to create [E], then visuzalized using package [f]  \n",
    "\n",
    "data set [Apple stock] uses definitions [dropna or interpolation], [closing, avg, start price], and [start and end dates].\n",
    "\n",
    "### Definition Metric choices:\n",
    "- accuracy\n",
    "    - mse - mean square error\n",
    "    - rmse - (square) root mean square error\n",
    "    - mae - mean absolute error\n",
    "\n",
    "### Selected definition of accuracy: \n",
    "- Lowest RMSE (square root mean squared error) between predicted values and actual values\n",
    "\n",
    "### fit assessment\n",
    "- train-test split: rolling \n",
    "    - train period window: x days\n",
    "    - test period window: x days\n",
    "- cross-validation: 3 fold\n",
    "    - period 1:\n",
    "        - train dates:\n",
    "        - test dates:\n",
    "    - period 2:\n",
    "        - train dates:\n",
    "        - test dates:\n",
    "    - period 3:\n",
    "        - train dates:\n",
    "        - test dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate HOW using code\n",
    "\n",
    "# import packages\n",
    "! pip install yfinance\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# read in data\n",
    "\n",
    "# check data before processing\n",
    "\n",
    "# process data\n",
    "\n",
    "# adjust model as needed\n",
    "\n",
    "# run\n",
    "\n",
    "# assess output\n",
    "\n",
    "# visualize\n",
    "\n",
    "# output data and charts somewhere"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
