{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Forecasting with the SARIMA Model\n",
    "\n",
    "The Seasonal Autoregressive Integrated Moving Average (SARIMA) Machine Learning Model should be added to your company's stock forecasting toolkit because it offers several advantages that can significantly improve forecasting accuracy. The SARIMA model is suitable when dealing with time-series data, like stock data, that exhibit both trend and seasonality. Our SARIMA model has demonstrated high accuracy (~96%). By incorporating SARIMA, you can enhance forecast precision, uncover key seasonal insights, and improve decision-making for better investment strategies.\n",
    "\n",
    "## Summary\n",
    "\n",
    "The SARIMA Model provides a robust framework for predicting stock prices and is a strong complement to the existing machine learning models used by stock market analysts. \n",
    "\n",
    "For this project, we applied the SARIMA model to predict stock prices for companies Apple (AAPL), Tesla (TSLA), and NVIDIA (NVDA). The goal was to assess the effectiveness of SARIMA in capturing seasonal patterns and underlying trends in stock price movements. We evaluated multiple time ranges of historical data (from 2015 to 2024) and found that using the most recent data (2021) yielded the most accurate predictions, with a forecast accuracy of ~96%.\n",
    "\n",
    "### Definition\n",
    "\n",
    "**SARIMA: Seasonal Autoregressive Integrated Moving Average Model**\n",
    "\n",
    "Key components of the SARIMA model include:\n",
    "* S (Seasonal): Includes seasonal autoregressive (SAR), seasonal differencing (SI), and seasonal moving average (SMA) terms to account for recurring patterns or cycles at specific intervals (e.g., yearly, quarterly).\n",
    "\n",
    "* AR (AutoRegressive): Models the relationship between an observation and a specified number of lagged observations.\n",
    "* I (Integrated): Differencing the series to make it stationary (i.e., removing trends). These trends make the data non-stationary, which can lead to unreliable predictions because the model might mistake the trend as part of the pattern rather than just noise.\n",
    "* MA (Moving Average): Models the relationship between an observation and the residual errors from a moving average model applied to lagged observations.\n",
    "\n",
    "### Benefits\n",
    "\n",
    "SARIMA's ability to capture the seasonal patterns and cyclic behavior inherent in sequential data, combined with its foundation in statistical time series analysis principles, enhances the credibility of stock forecasting processes.\n",
    "\n",
    "The model's interpretable parameters (S, AR, I, MA structure) provide a deeper understanding of the underlying dynamics driving stock price movements. With these parameters, this model is designed to:\n",
    "\n",
    "* notice the seasonal patterns present in the historical data (S component)\n",
    "* highlight the behavior of past observations (AR component)\n",
    "* understand the difference between noise and actual patterns (I component)\n",
    "* model the relationship between the current observation and past forecast errors (residuals) (MA component)\n",
    "\n",
    "#### Three Reasons to Use this Model\n",
    "\n",
    "1. Captures Stock Price Seasonality: SARIMA can model seasonal patterns in stock prices, such as recurring market cycles or quarterly trends, improving forecast accuracy\n",
    "\n",
    "2. Accounts for Time Dependencies: By using past stock prices (AR) and past forecast errors (MA), SARIMA can effectively capture trends and fluctuations in stock prices over time\n",
    "\n",
    "3. Provides Interpretability: The model's parameters offer insights into the factors influencing stock price movements, helping analysts understand the underlying dynamics and make informed investment decisions\n",
    "\n",
    "### Caveats\n",
    "\n",
    "It is important to note SARIMA's limitation in capturing external factors, such as news events or sudden market shocks, which may affect stock prices but are not directly incorporated into the model. Despite this limitation, SARIMA remains a valuable tool for predicting stock prices based on historical patterns and internal data dynamics.\n",
    "\n",
    "While SARIMA is a powerful tool for time series forecasting, there are several reasons why it might not be widely used by everyone, especially in stock forecasting:\n",
    "\n",
    "1. Complexity and Tuning: SARIMA requires careful parameter tuning, which can be time-consuming and technical.\n",
    "2. Assumes Stationarity: SARIMA works best with stationary data, but stock prices are often non-stationary and need preprocessing.\n",
    "3. Limited to Historical Data: It only uses past data, ignoring external factors like news or market sentiment, which can influence stock prices.\n",
    "4. Difficulty with Volatility: Stock prices are volatile and unpredictable, making SARIMA less effective for handling sudden market changes.\n",
    "5. Competition from Machine Learning: More flexible machine learning models, like XGBoost or LSTMs, are often preferred for their ability to handle complex data and capture non-linear relationships.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "For this project, four time ranges of historical data were evaluated to determine the optimal time lag and time steps to include in the model for three different stocks, AAPL (Apple Inc.), TSLA (Tesla Inc.), and NVDA (NVIDIA Corp.). It is important to test the accuracy of this model with stocks that exhibit all behaviors, which was the reason the three stocks were chosen. Historically, AAPL is known to be a safer stock, TSLA is known to be safe and volatile (fluctuates) and NVDA is known to be commonly volatile. By testing these three stocks, this SARIMA model's performance was analyzed with all ranges of behavior. In turn, improvements were made to the model's parameters to best work for all behavior.\n",
    "\n",
    "Predicted Dates: 06-01-2024 to 06-11-2024\n",
    "\n",
    "Historical Data Time Ranges:\n",
    "\n",
    "1. 01-01-2015 to 5-31-2024\n",
    "2. 01-01-2017 to 5-31-2024\n",
    "3. 01-01-2029 to 5-31-2024\n",
    "4. 01-01-2021 to 5-31-2024\n",
    "\n",
    "### Tests Used to Determine Accuracy\n",
    "\n",
    "Prediction accuracy was determined using comparison metrics, including R-squared, p-value, RMSE, MSE, MAPE, AIC, and BIC. Please refer to Definition Metric Choices section below for definition of each metric. These metrics were chosen as they are the most common metrics used by financial analysts to analyze model prediction accuracy.\n",
    "\n",
    "First, these metrics were specifically utilizated to compare time ranges. Once the optimal time ranges were chosen for each stock, the overall accuracy of the rool was analyzed. The metric with the most weight for determination of accuracy was the MAPE metric (Mean Absolute Percentage Error). The MAPE metric was emphasized more than other metrics due to it being ideal for stationary data. Since the SARIMA model's Integrated component caused the data to undergo differencing, thus making the data stationary, the MAPE metric was determined to be suitable for this application of SARIMA Model with stock forecasting.\n",
    "\n",
    "### Accuracy Results\n",
    "\n",
    "| **Stock**       | **Best Time Range** | **MAPE**     | **Overall Accuracy** | **Behavior**      |\n",
    "|-----------------|---------------------|--------------|----------------------|-------------------|\n",
    "| Apple (AAPL)    | 2021                | 2.3569%      | 97.6431%             | Stable            |\n",
    "| Tesla (TSLA)    | 2021                | 1.9726%      | 98.0274%             | Fluctuates        |\n",
    "| NVIDIA (NVDA)   | 2019                | 5.2467%      | 94.7533%             | Volatile          |\n",
    "\n",
    "**Average Accuracy: 96.8079%**\n",
    "\n",
    "The most recent time ranges yielded the most accurate results (2019, 2021). The finalized predictive model was thoroughly tested and found to have excellent accuracy, averaging ~96.8% for the recent time ranges (2019, 2021). Therefore, the SARIMA model is a valuable addition to a company's toolkit.\n",
    "\n",
    "   ### Kevin: Factors for Selecting Time Ranges:\n",
    "1. Accuracy (RMSE, MSE, MAPE) *which? why?* \n",
    "    1a. *seasonality*\n",
    "2. Speed\n",
    "3. Compute resource usage considerations\n",
    "4. Reproducibility\n",
    "5. World Events\n",
    "\n",
    "### **Kevin: Variance Among Stocks**?? (can you check her notes? I don't know what she wants in this section)\n",
    "### COME BACKKKKK!??\n",
    " They demonstrated high accuracy in capturing seasonal trends and underlying patterns in stock data. *see above*\n",
    "~~- They provided interpretable parameters that offered valuable insights into stock price movements.~~ *what does this really mean?*\n",
    "\n",
    "### A Detailed Analysis of SARIMA's Superiority Over Other Forecasting Methods\n",
    "\n",
    "#### Time Series Prediction vs. Other Machine Learning Tasks: \n",
    "\n",
    "SARIMA excels in time series analysis, making it highly effective for stock price predictions, where the temporal dependencies of historical data play a crucial role. In contrast, other machine learning models may struggle to capture these temporal patterns as effectively. \n",
    "\n",
    "SARIMA is specifically useful due to its interpretable, flexible, and effective for different-sized datasets, offering a reliable method for forecasting complex time series with seasonal effects.\n",
    "\n",
    "Specifics of the Model:\n",
    "\n",
    "- SARIMA: Captures seasonality and trends in data, making it robust for stocks with clear cyclical patterns (seasonal patterns), such as AAPL and TSLA. By leveraging its interpretable parameters, SARIMA provides a nuanced understanding of stock price movements and helps identify recurring trends. While it explicitly models seasonal patterns (e.g., yearly cycles), it also accounts for long-term trends, such as gradual increases or decreases in the data. The differencing component of SARIMA helps remove these trends to make the data stationary, enabling more accurate forecasting of underlying patterns, whether they are cyclical or directional.\n",
    "\n",
    "- Kevin: Contextual Effectiveness:\n",
    "(Not sure what to put here)\n",
    "\n",
    "#### The Disadvantages of Other Models:\n",
    "\n",
    "1. ARIMA (Autoregressive Integrated Moving Average):\n",
    "   - While ARIMA is effective for univariate time series data, it lacks the capability to model seasonal patterns as effectively as SARIMA. SARIMA extends ARIMA by incorporating seasonal components, making it more suitable for datasets with clear seasonal trends, such as stock prices.\n",
    "\n",
    "\n",
    "2. GARCH (Generalized Autoregressive Conditional Heteroskedasticity):\n",
    "   - GARCH models focus primarily on modeling volatility and are useful for forecasting the variance of returns rather than predicting actual prices. They are not designed for point forecasts of stock prices, limiting their applicability for direct price prediction tasks.\n",
    "\n",
    "3. XGBoost:\n",
    "   - XGBoost is a powerful machine learning algorithm that excels in classification and regression tasks. However, it does not inherently account for the temporal dependencies in time series data. Without careful feature engineering to incorporate time-based features, it may not perform as well for stock price predictions as SARIMA, which directly models these temporal relationships.\n",
    "\n",
    "4. Random Forest:\n",
    "   - Like XGBoost, Random Forest is a robust model for various prediction tasks but does not leverage the sequential nature of time series data. While it can provide accurate predictions with sufficient data, it typically requires extensive feature engineering to capture the temporal dynamics, which is automatically handled by SARIMA.\n",
    "\n",
    "5. TBATS (Trigonometric, Box-Cox Transformation, ARMA Errors, Trend, and Seasonal Components):\n",
    "   - TBATS is designed for complex seasonal patterns, but it can be computationally intensive and may require tuning of multiple parameters. In contrast, SARIMA offers a more straightforward framework for seasonal data without needing as much computational overhead.\n",
    "\n",
    "6. Prophet:\n",
    "   - Prophet is user-friendly and effective for forecasting time series data with strong seasonal effects and missing values. However, it may not be as robust for datasets with less clear seasonal patterns or when high-frequency forecasting is needed. SARIMA, with its statistical basis, can provide more granular control over the model parameters for precise forecasting.\n",
    "\n",
    "### SARIMA vs. Other Models\n",
    "While each of these models has its strengths, they may not capture the intricate seasonal patterns and temporal relationships present in stock price data as effectively as SARIMA. SARIMA’s design specifically caters to time series forecasting, allowing for more reliable predictions in financial contexts, particularly when historical data plays a critical role.\n",
    "\n",
    "## Process Overview\n",
    "\n",
    "### Final Workflow Summary for AAPL, NVDA, and TSLA Stock Predictions\n",
    "\n",
    "Utilizing historical stock price data from 2021 (AAPL, TSLA) and 2019 (NVDA), the SARIMA model was applied. Key packages such as statsmodels, pandas, and matplotlib were used to generate the most accurate predictions, with results visualized using matplotlib.\n",
    "\n",
    "The evaluation metrics employed include Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and prediction accuracy.\n",
    "\n",
    "### Definition Metric choices:\n",
    "The following metrics were considered when determining prediction accuracy:\n",
    "\n",
    "* R-squared (R²):\n",
    "R-squared represents the proportion of variance in the dependent variable explained by the independent variables. Values range from 0 (no fit) to 1 (perfect fit), with higher values indicating a better model fit.\n",
    "\n",
    "* P-value:\n",
    "The p-value tests the significance of results in hypothesis testing. A value less than 0.05 suggests strong evidence against the null hypothesis, indicating a statistically significant result.\n",
    "* RMSE (Root Mean Squared Error):\n",
    "RMSE measures the average magnitude of errors between predicted and actual values. Lower RMSE values indicate better predictive accuracy.\n",
    "* MSE (Mean Squared Error):\n",
    "MSE is the average of squared differences between predicted and actual values. Lower values suggest fewer errors and better model performance.\n",
    "* MAPE (Mean Absolute Percentage Error):\n",
    "MAPE calculates the average percentage difference between predicted and actual values. It’s used to assess forecasting accuracy, with lower values indicating better performance.\n",
    "* AIC (Akaike Information Criterion):\n",
    "AIC compares models based on fit and complexity, penalizing models with more parameters. A lower AIC suggests a more efficient model.\n",
    "* BIC (Bayesian Information Criterion):\n",
    "BIC is similar to AIC but applies a stronger penalty for additional parameters. It helps identify the simplest, best-fitting model with a lower BIC indicating better performance.\n",
    "\n",
    "\n",
    "**Selected Definition of Accuracy:** In this context, accuracy refers to how closely the SARIMA model's predicted values match the actual observed stock prices, as measured by low (less than 10%) MSE, RMSE, and MAPE scores.\n",
    "\n",
    "\n",
    "### Fit Assessment\n",
    "\n",
    "The Train-Test Split and Cross-Validation fit assessments were performed for our models. Both Train-Test Split and Cross-Validation are techniques for assessing the performance of machine learning models, but they differ in how they split the data and how many times they train and test the model. Below, you will see how evaluated the AAPL model's fit with the historical data time range from 01-01-2021 to 05-31-2024.\n",
    "\n",
    "- Train-Test split: Rolling \n",
    "    - Train period window: 684 days (80% of days stock market was open)\n",
    "    - Test period window: 172 days (20% of days stock market was open)\n",
    "    - Quarterly splitting was used (every three months)\n",
    "- Cross-Validation: 3-Fold\n",
    "   - Period 1: \n",
    "      - Train dates: 2021-01-01 to 2022-12-31 (2 years)\n",
    "      - Test dates: 2023-01-01 to 2023-12-31 (1 year)\n",
    "   - Period 2:\n",
    "      - Train dates: 2021-01-01 to 2023-06-30 (2.5 years)\n",
    "      - Test dates: 2023-07-01 to 2024-05-31 (1 year)\n",
    "   - Period 3:\n",
    "      - Train dates: 2021-01-01 to 2023-12-31 (3 years)\n",
    "      - Test dates: 2024-01-01 to 2024-05-31 (5 months)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Step-by-Step Guide to Implementing the SARIMA Model with the AAPL Stock**\n",
    "\n",
    "#### For this example, we will guide you step-by-step in implementing the SARIMA model for the AAPL stock.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Import Packages**\n",
    "\n",
    "Necessary packages were imported into Python. Packages important to note were pandas, numpy, yfinance, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "\n",
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Packages specific to project\n",
    "import statsmodels.api as sm\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Download Historical Data**\n",
    "\n",
    "The stock ticker was specified, and multiple years of historical data for the selected stock were downloaded and stored in the stock_select_str variable. In this case, the stock was AAPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Step 2\n",
    "\n",
    "# Specify stock ticker\n",
    "stock_select_str = \"AAPL\"\n",
    "\n",
    "# Initial load run\n",
    "stock_data = yf.download(stock_select_str, start='2021-01-01', end='2024-05-31', interval='1d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Check Data Before Processing**\n",
    "\n",
    "The historical data for AAPL was checked before processing. First, the head of the dataframe was printed to verify the right dates were downloaded for our set of historical data. Below, you will see the first date is Jan 4th, 2021 (the first business day of the year and the first day of the year the stock market was open.) From this, it was determined the historical data set was correct. Second, more information was printed, with the intent of seeing the count of each column in the dataframe. Below, there is a count of 857 displayed for each column, meaning the right amount of days were pulled.\n",
    "\n",
    "Lastly, the index of the stock_data DataFrame was first converted to a DateTimeIndex to enable easy filtering. Then, weekend data was filtered out by retaining only rows where the day of the week was less than 5 (Monday to Friday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning of historical data df:\n",
      "\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2021-01-04  133.520004  133.610001  126.760002  129.410004  126.544228   \n",
      "2021-01-05  128.889999  131.740005  128.429993  131.009995  128.108795   \n",
      "2021-01-06  127.720001  131.050003  126.379997  126.599998  123.796440   \n",
      "2021-01-07  128.360001  131.630005  127.860001  130.919998  128.020752   \n",
      "2021-01-08  132.429993  132.630005  130.229996  132.050003  129.125717   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2021-01-04  143301900  \n",
      "2021-01-05   97664900  \n",
      "2021-01-06  155088000  \n",
      "2021-01-07  109578200  \n",
      "2021-01-08  105158200  \n",
      "\n",
      "Extra information:\n",
      "\n",
      "              Open        High         Low       Close   Adj Close  \\\n",
      "count  857.000000  857.000000  857.000000  857.000000  857.000000   \n",
      "mean   158.865963  160.564808  157.292415  158.995519  157.163260   \n",
      "std     20.422276   20.367330   20.476360   20.424938   20.853998   \n",
      "min    119.029999  120.400002  116.209999  116.360001  113.953224   \n",
      "25%    143.250000  144.899994  141.509995  143.240005  141.267639   \n",
      "50%    158.860001  160.710007  156.320007  157.960007  156.247604   \n",
      "75%    174.910004  176.649994  173.449997  175.059998  173.093689   \n",
      "max    198.020004  199.619995  197.000000  198.110001  197.144180   \n",
      "\n",
      "             Volume  \n",
      "count  8.570000e+02  \n",
      "mean   7.697864e+07  \n",
      "std    2.777241e+07  \n",
      "min    2.404830e+07  \n",
      "25%    5.596280e+07  \n",
      "50%    7.137960e+07  \n",
      "75%    9.095670e+07  \n",
      "max    1.954327e+08  \n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "\n",
    "# Check data before processing\n",
    "print(\"Beginning of historical data df:\\n\\n\", stock_data.head())\n",
    "print(\"\\nExtra information:\\n\\n\", stock_data.describe())\n",
    "\n",
    "# Ensure the index is a DateTimeIndex for easy filtering\n",
    "stock_data.index = pd.to_datetime(stock_data.index)\n",
    "# Filter out weekends\n",
    "stock_data = stock_data[stock_data.index.to_series().dt.dayofweek < 5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Process Historical Data with Model**\n",
    "\n",
    "First, the SARIMA Model Parameters were defined.\n",
    "\n",
    "#### **Kevin (please fill in below)**\n",
    "- SARIMA: (s)easonal + (i)ntegrated + (a)uto (r)egression + (m)oving (a)verage\n",
    "    - p = number of lagged values included:\n",
    "    - q = number of time steps in moving average:\n",
    "    - d = number of differencing sequences: \n",
    "    - m = number of observations per year:\n",
    "    - smoothing choice: explain\n",
    "    - final model choice: SARIMA(p, d, q)(P, D, Q)m\n",
    "- p: 1 - 3\n",
    "- q: 1 - 3\n",
    "- d: none\n",
    "- m: 12\n",
    "- P: 0\n",
    "- D: 1\n",
    "- Q: ?\n",
    "\n",
    "Next, The process_model function was defined to create and configure a SARIMA (Seasonal AutoRegressive Integrated Moving Average) model. The function uses \"Close\" price of the stock dataframe. The auto_arima function was set up to optimize the SARIMA model parameters (like p, q, P, and Q) with specific settings: a yearly seasonal cycle (m=12), seasonal differencing of order 1, and stepwise selection for efficiency. After fitting, the model was returned for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "\n",
    "# Define the process_model function\n",
    "def process_model(stock_transformed):\n",
    "    print(\"Processing SARIMA model...\\n\")\n",
    "    \n",
    "    sarima_model = pm.auto_arima(stock_transformed[\"Close\"], start_p=1, start_q=1,\n",
    "                                  test='adf',\n",
    "                                  max_p=3, max_q=3,\n",
    "                                  m=12,  # 12 is the frequency of the cycle (yearly)\n",
    "                                  start_P=0,\n",
    "                                  seasonal=True,  # Set to seasonal\n",
    "                                  d=None,\n",
    "                                  D=1,  # Order of the seasonal differencing\n",
    "                                  trace=False,\n",
    "                                  error_action='ignore',\n",
    "                                  suppress_warnings=True,\n",
    "                                  stepwise=True)\n",
    "    \n",
    "    return sarima_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When passing historical stock data through the auto_arima function (see below code block), this will fit the data in the model by doing the following:\n",
    "\n",
    "- Stationarity Check: It tests whether the data is stationary using the Augmented Dickey-Fuller test (test='adf').\n",
    "- Differencing: If necessary, it applies differencing to make the data stationary.\n",
    "- Seasonality Detection: It looks for any seasonal patterns and models them accordingly (e.g., yearly cycles).\n",
    "- Parameter Optimization: It tries different combinations of the AR, MA, seasonal AR, and seasonal MA parameters to find the optimal model that minimizes the AIC/BIC (Akaike/Bayesian Information Criteria).\n",
    "- Model Return: After fitting, the function returns the SARIMA model that has been trained on the historical data (i.e., the model that can now make predictions based on past data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SARIMA model...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the SARIMA model \n",
    "sarima_model = process_model(stock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Run Predictions**\n",
    "\n",
    "The predictions were run by calling a built-in predict function. The n_forecast variable is 12 because of the number of days to forecast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliawilliams/.pyenv/versions/3.9.2/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/Users/juliawilliams/.pyenv/versions/3.9.2/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "# Step 5\n",
    "\n",
    "# Run predictions\n",
    "n_forecast = 12\n",
    "forecast, conf_int = sarima_model.predict(n_periods=n_forecast, return_conf_int=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEREEE\n",
      " 599\n",
      "HEREEE\n",
      " 257\n",
      "Period 1:\n",
      "  Train dates: (Timestamp('2021-01-04 00:00:00'), Timestamp('2022-09-14 00:00:00'))\n",
      "  Test dates: (Timestamp('2022-09-15 00:00:00'), Timestamp('2024-05-30 00:00:00'))\n",
      "\n",
      "traindata\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2021-01-04  133.520004  133.610001  126.760002  129.410004  126.544228   \n",
      "2021-01-05  128.889999  131.740005  128.429993  131.009995  128.108795   \n",
      "2021-01-06  127.720001  131.050003  126.379997  126.599998  123.796440   \n",
      "2021-01-07  128.360001  131.630005  127.860001  130.919998  128.020752   \n",
      "2021-01-08  132.429993  132.630005  130.229996  132.050003  129.125717   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2022-09-08  154.639999  156.360001  152.679993  154.460007  152.599472   \n",
      "2022-09-09  155.470001  157.820007  154.750000  157.369995  155.474426   \n",
      "2022-09-12  159.589996  164.259995  159.300003  163.429993  161.461426   \n",
      "2022-09-13  159.899994  160.539993  153.369995  153.839996  151.986938   \n",
      "2022-09-14  154.789993  157.100006  153.610001  155.309998  153.439224   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2021-01-04  143301900  \n",
      "2021-01-05   97664900  \n",
      "2021-01-06  155088000  \n",
      "2021-01-07  109578200  \n",
      "2021-01-08  105158200  \n",
      "...               ...  \n",
      "2022-09-08   84923800  \n",
      "2022-09-09   68028800  \n",
      "2022-09-12  104956000  \n",
      "2022-09-13  122656600  \n",
      "2022-09-14   87965400  \n",
      "\n",
      "[428 rows x 6 columns]\n",
      "testdata\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2022-09-15  154.649994  155.240005  151.380005  152.369995  150.534637   \n",
      "2022-09-16  151.210007  151.350006  148.369995  150.699997  148.884735   \n",
      "2022-09-19  149.309998  154.559998  149.100006  154.479996  152.619232   \n",
      "2022-09-20  153.399994  158.080002  153.080002  156.899994  155.010071   \n",
      "2022-09-21  157.339996  158.740005  153.600006  153.720001  151.868378   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2024-05-23  190.979996  191.000000  186.630005  186.880005  186.458801   \n",
      "2024-05-24  188.820007  190.580002  188.039993  189.979996  189.551804   \n",
      "2024-05-28  191.509995  193.000000  189.100006  189.990005  189.561798   \n",
      "2024-05-29  189.610001  192.250000  189.509995  190.289993  189.861115   \n",
      "2024-05-30  190.759995  192.179993  190.630005  191.289993  190.858856   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2022-09-15   90481100  \n",
      "2022-09-16  162278800  \n",
      "2022-09-19   81474200  \n",
      "2022-09-20  107689800  \n",
      "2022-09-21  101696800  \n",
      "...               ...  \n",
      "2024-05-23   51005900  \n",
      "2024-05-24   36294600  \n",
      "2024-05-28   52280100  \n",
      "2024-05-29   53068000  \n",
      "2024-05-30   49947900  \n",
      "\n",
      "[429 rows x 6 columns]\n",
      "Processing SARIMA model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliawilliams/.pyenv/versions/3.9.2/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/Users/juliawilliams/.pyenv/versions/3.9.2/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecasstttt 428    154.262325\n",
      "429    156.812420\n",
      "430    157.219351\n",
      "431    159.074026\n",
      "432    159.074005\n",
      "          ...    \n",
      "851    155.338166\n",
      "852    154.997057\n",
      "853    154.328502\n",
      "854    155.287463\n",
      "855    153.385077\n",
      "Length: 428, dtype: float64\n",
      "            Forecast\n",
      "2022-09-15       NaN\n",
      "2022-09-16       NaN\n",
      "2022-09-19       NaN\n",
      "2022-09-20       NaN\n",
      "2022-09-21       NaN\n",
      "...              ...\n",
      "2024-04-30       NaN\n",
      "2024-05-01       NaN\n",
      "2024-05-02       NaN\n",
      "2024-05-03       NaN\n",
      "2024-05-06       NaN\n",
      "\n",
      "[428 rows x 1 columns]\n",
      "(428,)\n",
      "428    154.262325\n",
      "429    156.812420\n",
      "430    157.219351\n",
      "431    159.074026\n",
      "432    159.074005\n",
      "dtype: float64 \n",
      "\n",
      "851    155.338166\n",
      "852    154.997057\n",
      "853    154.328502\n",
      "854    155.287463\n",
      "855    153.385077\n",
      "dtype: float64 \n",
      "\n",
      "Period 2:\n",
      "  Train dates: (Timestamp('2021-01-04 00:00:00'), Timestamp('2023-05-19 00:00:00'))\n",
      "  Test dates: (Timestamp('2023-05-22 00:00:00'), Timestamp('2024-05-30 00:00:00'))\n",
      "\n",
      "traindata\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2021-01-04  133.520004  133.610001  126.760002  129.410004  126.544228   \n",
      "2021-01-05  128.889999  131.740005  128.429993  131.009995  128.108795   \n",
      "2021-01-06  127.720001  131.050003  126.379997  126.599998  123.796440   \n",
      "2021-01-07  128.360001  131.630005  127.860001  130.919998  128.020752   \n",
      "2021-01-08  132.429993  132.630005  130.229996  132.050003  129.125717   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2023-05-15  173.160004  173.210007  171.470001  172.070007  170.775253   \n",
      "2023-05-16  171.990005  173.139999  171.800003  172.070007  170.775253   \n",
      "2023-05-17  171.710007  172.929993  170.419998  172.690002  171.390564   \n",
      "2023-05-18  173.000000  175.240005  172.580002  175.050003  173.732819   \n",
      "2023-05-19  176.389999  176.389999  174.940002  175.160004  173.841980   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2021-01-04  143301900  \n",
      "2021-01-05   97664900  \n",
      "2021-01-06  155088000  \n",
      "2021-01-07  109578200  \n",
      "2021-01-08  105158200  \n",
      "...               ...  \n",
      "2023-05-15   37266700  \n",
      "2023-05-16   42110300  \n",
      "2023-05-17   57951600  \n",
      "2023-05-18   65496700  \n",
      "2023-05-19   55772400  \n",
      "\n",
      "[599 rows x 6 columns]\n",
      "testdata\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2023-05-22  173.979996  174.710007  173.449997  174.199997  172.889206   \n",
      "2023-05-23  173.130005  173.380005  171.279999  171.559998  170.269073   \n",
      "2023-05-24  171.089996  172.419998  170.520004  171.839996  170.546951   \n",
      "2023-05-25  172.410004  173.899994  171.690002  172.990005  171.688309   \n",
      "2023-05-26  173.320007  175.770004  173.110001  175.429993  174.109940   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2024-05-23  190.979996  191.000000  186.630005  186.880005  186.458801   \n",
      "2024-05-24  188.820007  190.580002  188.039993  189.979996  189.551804   \n",
      "2024-05-28  191.509995  193.000000  189.100006  189.990005  189.561798   \n",
      "2024-05-29  189.610001  192.250000  189.509995  190.289993  189.861115   \n",
      "2024-05-30  190.759995  192.179993  190.630005  191.289993  190.858856   \n",
      "\n",
      "              Volume  \n",
      "Date                  \n",
      "2023-05-22  43570900  \n",
      "2023-05-23  50747300  \n",
      "2023-05-24  45143500  \n",
      "2023-05-25  56058300  \n",
      "2023-05-26  54835000  \n",
      "...              ...  \n",
      "2024-05-23  51005900  \n",
      "2024-05-24  36294600  \n",
      "2024-05-28  52280100  \n",
      "2024-05-29  53068000  \n",
      "2024-05-30  49947900  \n",
      "\n",
      "[258 rows x 6 columns]\n",
      "Processing SARIMA model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliawilliams/.pyenv/versions/3.9.2/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/Users/juliawilliams/.pyenv/versions/3.9.2/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecasstttt 599     175.085831\n",
      "600     178.462054\n",
      "601     178.072236\n",
      "602     176.351551\n",
      "603     176.102946\n",
      "           ...    \n",
      "1022    179.577695\n",
      "1023    179.823884\n",
      "1024    179.085718\n",
      "1025    177.640282\n",
      "1026    178.345940\n",
      "Length: 428, dtype: float64\n",
      "            Forecast\n",
      "2023-05-22       NaN\n",
      "2023-05-23       NaN\n",
      "2023-05-24       NaN\n",
      "2023-05-25       NaN\n",
      "2023-05-26       NaN\n",
      "...              ...\n",
      "2025-01-02       NaN\n",
      "2025-01-03       NaN\n",
      "2025-01-06       NaN\n",
      "2025-01-07       NaN\n",
      "2025-01-08       NaN\n",
      "\n",
      "[428 rows x 1 columns]\n",
      "(428,)\n",
      "599    175.085831\n",
      "600    178.462054\n",
      "601    178.072236\n",
      "602    176.351551\n",
      "603    176.102946\n",
      "dtype: float64 \n",
      "\n",
      "1022    179.577695\n",
      "1023    179.823884\n",
      "1024    179.085718\n",
      "1025    177.640282\n",
      "1026    178.345940\n",
      "dtype: float64 \n",
      "\n",
      "Period 3:\n",
      "  Train dates: (Timestamp('2021-01-04 00:00:00'), Timestamp('2022-09-14 00:00:00'))\n",
      "  Test dates: (Timestamp('2022-09-15 00:00:00'), Timestamp('2024-05-30 00:00:00'))\n",
      "\n",
      "traindata\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2021-01-04  133.520004  133.610001  126.760002  129.410004  126.544228   \n",
      "2021-01-05  128.889999  131.740005  128.429993  131.009995  128.108795   \n",
      "2021-01-06  127.720001  131.050003  126.379997  126.599998  123.796440   \n",
      "2021-01-07  128.360001  131.630005  127.860001  130.919998  128.020752   \n",
      "2021-01-08  132.429993  132.630005  130.229996  132.050003  129.125717   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2022-09-08  154.639999  156.360001  152.679993  154.460007  152.599472   \n",
      "2022-09-09  155.470001  157.820007  154.750000  157.369995  155.474426   \n",
      "2022-09-12  159.589996  164.259995  159.300003  163.429993  161.461426   \n",
      "2022-09-13  159.899994  160.539993  153.369995  153.839996  151.986938   \n",
      "2022-09-14  154.789993  157.100006  153.610001  155.309998  153.439224   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2021-01-04  143301900  \n",
      "2021-01-05   97664900  \n",
      "2021-01-06  155088000  \n",
      "2021-01-07  109578200  \n",
      "2021-01-08  105158200  \n",
      "...               ...  \n",
      "2022-09-08   84923800  \n",
      "2022-09-09   68028800  \n",
      "2022-09-12  104956000  \n",
      "2022-09-13  122656600  \n",
      "2022-09-14   87965400  \n",
      "\n",
      "[428 rows x 6 columns]\n",
      "testdata\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2022-09-15  154.649994  155.240005  151.380005  152.369995  150.534637   \n",
      "2022-09-16  151.210007  151.350006  148.369995  150.699997  148.884735   \n",
      "2022-09-19  149.309998  154.559998  149.100006  154.479996  152.619232   \n",
      "2022-09-20  153.399994  158.080002  153.080002  156.899994  155.010071   \n",
      "2022-09-21  157.339996  158.740005  153.600006  153.720001  151.868378   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2024-05-23  190.979996  191.000000  186.630005  186.880005  186.458801   \n",
      "2024-05-24  188.820007  190.580002  188.039993  189.979996  189.551804   \n",
      "2024-05-28  191.509995  193.000000  189.100006  189.990005  189.561798   \n",
      "2024-05-29  189.610001  192.250000  189.509995  190.289993  189.861115   \n",
      "2024-05-30  190.759995  192.179993  190.630005  191.289993  190.858856   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2022-09-15   90481100  \n",
      "2022-09-16  162278800  \n",
      "2022-09-19   81474200  \n",
      "2022-09-20  107689800  \n",
      "2022-09-21  101696800  \n",
      "...               ...  \n",
      "2024-05-23   51005900  \n",
      "2024-05-24   36294600  \n",
      "2024-05-28   52280100  \n",
      "2024-05-29   53068000  \n",
      "2024-05-30   49947900  \n",
      "\n",
      "[429 rows x 6 columns]\n",
      "Processing SARIMA model...\n",
      "\n",
      "forecasstttt 428    154.262325\n",
      "429    156.812420\n",
      "430    157.219351\n",
      "431    159.074026\n",
      "432    159.074005\n",
      "          ...    \n",
      "851    155.338166\n",
      "852    154.997057\n",
      "853    154.328502\n",
      "854    155.287463\n",
      "855    153.385077\n",
      "Length: 428, dtype: float64\n",
      "            Forecast\n",
      "2022-09-15       NaN\n",
      "2022-09-16       NaN\n",
      "2022-09-19       NaN\n",
      "2022-09-20       NaN\n",
      "2022-09-21       NaN\n",
      "...              ...\n",
      "2024-04-30       NaN\n",
      "2024-05-01       NaN\n",
      "2024-05-02       NaN\n",
      "2024-05-03       NaN\n",
      "2024-05-06       NaN\n",
      "\n",
      "[428 rows x 1 columns]\n",
      "(428,)\n",
      "428    154.262325\n",
      "429    156.812420\n",
      "430    157.219351\n",
      "431    159.074026\n",
      "432    159.074005\n",
      "dtype: float64 \n",
      "\n",
      "851    155.338166\n",
      "852    154.997057\n",
      "853    154.328502\n",
      "854    155.287463\n",
      "855    153.385077\n",
      "dtype: float64 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliawilliams/.pyenv/versions/3.9.2/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/Users/juliawilliams/.pyenv/versions/3.9.2/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    # Evaluate the predictions (using RMSE and MAE as example metrics)\\n    mae = mean_absolute_error(test_data[\\'Close\\'], forecast)\\n    rmse = np.sqrt(mean_squared_error(test_data[\\'Close\\'], forecast))\\n    \\n    print(f\"  MAE (Mean Absolute Error) for Period {i+1}: {mae}\")\\n    print(f\"  RMSE (Root Mean Squared Error) for Period {i+1}: {rmse}\")\\n    print(\"------------\\n\")\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pmdarima as pm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Total number of data points\n",
    "total_days = len(stock_data)\n",
    "\n",
    "# Defining the train and test periods based on your requested specifications\n",
    "train_period_days = int(0.5 * total_days)  # 50% of the total period\n",
    "test_period_days = int(0.5 * total_days)  # 50% of the total period \n",
    "\n",
    "# Set initial train-test split periods based on your 3-fold cross-validation requirement\n",
    "rolling_splits = []\n",
    "\n",
    "# Period 1\n",
    "train_period_1 = stock_data.iloc[:train_period_days]  # Train for 684 days\n",
    "\n",
    "test_period_1 = stock_data.iloc[train_period_days:]  # Test for 172 days\n",
    "#print(\"HEREEE\\n\", test_period_1)\n",
    "\n",
    "rolling_splits.append({\n",
    "    \"train_dates\": (train_period_1.index[0], train_period_1.index[-1]),\n",
    "    \"test_dates\": (test_period_1.index[0], test_period_1.index[-1])\n",
    "})\n",
    "\n",
    "#print(rolling_splits)\n",
    "\n",
    "# Defining the train and test periods based on your requested specifications\n",
    "train_period_days2 = int(0.7 * total_days)  # 70% of the total period\n",
    "print(\"HEREEE\\n\", train_period_days2)\n",
    "test_period_days2 = int(0.3 * total_days)  # 30% of the total period \n",
    "print(\"HEREEE\\n\", test_period_days2)\n",
    "# Period 2 (Extend training window to 2.5 years)\n",
    "train_period_2 = stock_data.iloc[:train_period_days2]  # Train for 2.5 years (1007 + 252 days)\n",
    "test_period_2 = stock_data.iloc[train_period_days2:]  # Test for 252 days\n",
    "rolling_splits.append({\n",
    "    \"train_dates\": (train_period_2.index[0], train_period_2.index[-1]),\n",
    "    \"test_dates\": (test_period_2.index[0], test_period_2.index[-1])\n",
    "})\n",
    "\n",
    "# Defining the train and test periods based on your requested specifications\n",
    "train_period_day3 = int(0.9 * total_days)  # 50% of the total period\n",
    "test_period_days3 = int(0.1 * total_days)  # 50% of the total period \n",
    "\n",
    "# Period 3 (Extend training window to 3 years)\n",
    "train_period_3 = stock_data.iloc[:train_period_days]  # Train for 3 years (1007 + 252 + 252 days)\n",
    "test_period_3 = stock_data.iloc[train_period_days:]  # Test for 152 days (5 months)\n",
    "rolling_splits.append({\n",
    "    \"train_dates\": (train_period_3.index[0], train_period_3.index[-1]),\n",
    "    \"test_dates\": (test_period_3.index[0], test_period_3.index[-1])\n",
    "})\n",
    "\n",
    "# Step 2: Perform train-test split for each period and fit/predict with SARIMA\n",
    "for i, split in enumerate(rolling_splits):\n",
    "    print(f\"Period {i+1}:\")\n",
    "    #print (split)\n",
    "    print(f\"  Train dates: {split['train_dates']}\")\n",
    "    print(f\"  Test dates: {split['test_dates']}\\n\")\n",
    "\n",
    "    # Get the actual data for training and testing\n",
    "    train_data = stock_data.loc[split[\"train_dates\"][0]:split[\"train_dates\"][1]]\n",
    "    test_data = stock_data.loc[split[\"test_dates\"][0]:split[\"test_dates\"][1]]\n",
    "    print(\"traindata\\n\", train_data)\n",
    "    print(\"testdata\\n\", test_data)\n",
    "\n",
    "    # Fit the SARIMA model on the training data\n",
    "    sarima_model = process_model(train_data)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    forecast, conf_int = sarima_model.predict(n_periods=test_period_days, return_conf_int=True)\n",
    "    #test_data = test_data.drop(test_data.index[-1])\n",
    "    # Plot predictions and confidence intervals (optional)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    #plt.plot(test_data.index, test_data['Close'], color='blue', label='Actual')\n",
    "    #print(test_data.shape)\n",
    "    #print(test_data.head(), \"\\n\")\n",
    "    #print(test_data.tail(), \"\\n\")\n",
    "\n",
    "    print(\"forecasstttt\", forecast)\n",
    "    forecast_dates = pd.date_range(start=test_data.index[0], periods=test_period_days, freq='B')\n",
    "    forecast_df = pd.DataFrame(forecast, index=forecast_dates, columns=['Forecast'])\n",
    "    print(forecast_df)\n",
    "    #size_predict = forecast.size\n",
    "    #first_date = forecast.loc[0].date\n",
    "    #print(size_predict)\n",
    "    #actual = stock_data[size_predict]\n",
    "    #print(actual)\n",
    "\n",
    "\n",
    "    print(forecast.shape)\n",
    "    print(forecast.head(), \"\\n\")\n",
    "    print(forecast.tail(), \"\\n\")\n",
    "    '''\n",
    "    plt.plot(test_data.index, forecast, color='red', linestyle='--', label='Forecast')\n",
    "    plt.fill_between(test_data.index, conf_int[:, 0], conf_int[:, 1], color='gray', alpha=0.2)\n",
    "    plt.title(f\"Period {i+1}: Actual vs Forecast\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    '''\n",
    "\n",
    "'''\n",
    "    # Evaluate the predictions (using RMSE and MAE as example metrics)\n",
    "    mae = mean_absolute_error(test_data['Close'], forecast)\n",
    "    rmse = np.sqrt(mean_squared_error(test_data['Close'], forecast))\n",
    "    \n",
    "    print(f\"  MAE (Mean Absolute Error) for Period {i+1}: {mae}\")\n",
    "    print(f\"  RMSE (Root Mean Squared Error) for Period {i+1}: {rmse}\")\n",
    "    print(\"------------\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: The output was assessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Assess output\n",
    "print(f\"Forecasted values: {forecast}\")\n",
    "print(f\"Confidence intervals: {conf_int}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Chart Actuals Against Forecast\n",
    "Actual closing prices were imported for the stock AAPL into the real_values DataFrame, using data up to June 12, 2024. It then filtered this data to include only the closing prices from January 1 to June 11, 2024, which were stored in plot_real.\n",
    "\n",
    "A plot was created with a figure size of 12x8 inches, displaying the historical closing prices alongside the forecasted closing prices. The forecast was plotted starting from June 1, 2024, extending for the specified number of forecasted days (n_forecast) on business days (freq='B'). A shaded area representing the 95% confidence interval was added around the forecast line. Finally, the x-axis range was set from April 1 to June 11, 2024, and labels for the title, x-axis, y-axis, and legend were included for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Visualize\n",
    "# Import actual closing prices into real_values dataframe\n",
    "real_values = yf.download(\"AAPL\", end='2024-06-12')\n",
    "plot_real = real_values.loc['2024-01-01':'2024-06-11', 'Close']\n",
    "    \n",
    "# Plot the extended historical data\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(plot_real, label='Historical Close Prices')\n",
    "plt.plot(pd.date_range(start='2024-06-01', periods=n_forecast, freq='B'), \n",
    "         forecast, label='Forecasted Close Prices', color='orange')\n",
    "plt.fill_between(pd.date_range(start='2024-06-01', periods=n_forecast, freq='B'), \n",
    "                 conf_int[:, 0], conf_int[:, 1], color='gray', alpha=0.5, label='95% Confidence Interval')\n",
    "\n",
    "# Adjust the x-axis and other labels\n",
    "plt.xlim(pd.Timestamp('2024-04-01'), pd.Timestamp('2024-06-11'))\n",
    "plt.title(f'Close Price Forecast for {stock_select_str}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: \n",
    "The print_metrics function outputs the chosen comparison metrics for determining accuracy (RMSE, MSE, and MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(actual, predicted):\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    \n",
    "    # Calculate MAPE (Mean Absolute Percentage Error)\n",
    "    actual_values = np.array(actual)\n",
    "    predicted_values = np.array(predicted)\n",
    "    mape = np.mean(np.abs((actual_values - predicted_values) / actual_values[actual_values != 0])) * 100 if np.any(actual_values != 0) else np.nan\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Example usage (assuming 'forecast' and 'plot_real[-n_forecast:]' are defined)\n",
    "print_metrics(plot_real[-n_forecast:], forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load stock data (using a sample ticker here, e.g., \"AAPL\")\n",
    "stock_ticker = \"AAPL\"\n",
    "stock_data = yf.download(stock_ticker, start=\"2021-01-01\", end=\"2024-05-31\", interval=\"1d\")\n",
    "\n",
    "# Calculate the total number of days in the dataset\n",
    "total_days = len(stock_data)\n",
    "train_days = int(0.8 * total_days)  # 80% of the data for training\n",
    "test_days = total_days - train_days  # 20% of the data for testing\n",
    "\n",
    "# Define rolling periods (quarterly)\n",
    "rolling_splits = []\n",
    "\n",
    "# Period 1 (Train on first 80%, Test on the next 20%)\n",
    "train_period_1 = stock_data.iloc[:train_days]\n",
    "test_period_1 = stock_data.iloc[train_days:train_days+test_days]\n",
    "rolling_splits.append({\"train_dates\": (train_period_1.index[0], train_period_1.index[-1]), \n",
    "                       \"test_dates\": (test_period_1.index[0], test_period_1.index[-1])})\n",
    "\n",
    "# Period 2 (Roll forward by 3 months, Train on 80%, Test on the next 20%)\n",
    "train_period_2 = stock_data.iloc[:train_days + 30]  # Add 30 days for training\n",
    "test_period_2 = stock_data.iloc[train_days + 30:train_days + 30 + test_days]\n",
    "rolling_splits.append({\"train_dates\": (train_period_2.index[0], train_period_2.index[-1]), \n",
    "                       \"test_dates\": (test_period_2.index[0], test_period_2.index[-1])})\n",
    "\n",
    "# Period 3 (Roll forward again, Train on 80%, Test on the next 20%)\n",
    "train_period_3 = stock_data.iloc[:train_days + 60]  # Add another 30 days for training\n",
    "test_period_3 = stock_data.iloc[train_days + 60:train_days + 60 + test_days]\n",
    "rolling_splits.append({\"train_dates\": (train_period_3.index[0], train_period_3.index[-1]), \n",
    "                       \"test_dates\": (test_period_3.index[0], test_period_3.index[-1])})\n",
    "\n",
    "# Output train-test splits for each period\n",
    "for i, split in enumerate(rolling_splits):\n",
    "    print(f\"Period {i+1}:\")\n",
    "    print(f\"  Train dates: {split['train_dates']}\")\n",
    "    print(f\"  Test dates: {split['test_dates']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Cross-Validation Splits\n",
    "cv_splits = []\n",
    "\n",
    "# Fold 1 (Train on 2021-2022, Test on 2023)\n",
    "train_1 = stock_data.loc[\"2021-01-01\":\"2022-12-31\"]\n",
    "test_1 = stock_data.loc[\"2023-01-01\":\"2023-12-31\"]\n",
    "cv_splits.append({\"train_dates\": (train_1.index[0], train_1.index[-1]), \"test_dates\": (test_1.index[0], test_1.index[-1])})\n",
    "\n",
    "# Fold 2 (Train on 2021-2023, Test on 2023 mid-year to 2024)\n",
    "train_2 = stock_data.loc[\"2021-01-01\":\"2023-06-30\"]\n",
    "test_2 = stock_data.loc[\"2023-07-01\":\"2024-05-31\"]\n",
    "cv_splits.append({\"train_dates\": (train_2.index[0], train_2.index[-1]), \"test_dates\": (test_2.index[0], test_2.index[-1])})\n",
    "\n",
    "# Fold 3 (Train on 2021-2023, Test on 2024)\n",
    "train_3 = stock_data.loc[\"2021-01-01\":\"2023-12-31\"]\n",
    "test_3 = stock_data.loc[\"2024-01-01\":\"2024-05-31\"]\n",
    "cv_splits.append({\"train_dates\": (train_3.index[0], train_3.index[-1]), \"test_dates\": (test_3.index[0], test_3.index[-1])})\n",
    "\n",
    "# Output Cross-Validation Splits\n",
    "for i, split in enumerate(cv_splits):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"  Train dates: {split['train_dates']}\")\n",
    "    print(f\"  Test dates: {split['test_dates']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
